[Script Info]
Title: Converted from WebVTT
ScriptType: v4.00+
WrapStyle: 0
PlayResX: 1280
PlayResY: 720
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,Alignment,MarginL,MarginR,MarginV,Encoding
Style: Default, 微軟正黑體,48,&H0080FFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,1,0,1,2,0,2,1,1,40,1
Style: Secondary,Helvetica,12,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,0,2,1,1,40,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:02.00,Default,,0,0,0,,哈囉, 歡迎收聽保哥帶你聽
Dialogue: 0,0:00:02.00,0:00:07.00,Default,,0,0,0,,今天我們要來好好聊聊一個很熱門的新東西
Dialogue: 0,0:00:07.00,0:00:09.00,Default,,0,0,0,,最新的大型語言模型家族
Dialogue: 0,0:00:09.00,0:00:13.00,Default,,0,0,0,,叫做 Qwen3, 也就是千問三
Dialogue: 0,0:00:13.00,0:00:14.00,Default,,0,0,0,,我們手上這一份
Dialogue: 0,0:00:14.00,0:00:18.00,Default,,0,0,0,,就是千問團隊他們剛剛才發佈的技術報告
Dialogue: 0,0:00:18.00,0:00:20.00,Default,,0,0,0,,哇, 內容真的很多
Dialogue: 0,0:00:20.00,0:00:22.00,Default,,0,0,0,,今天的任務很簡單
Dialogue: 0,0:00:22.00,0:00:24.00,Default,,0,0,0,,就是要幫你從這份報告裡面
Dialogue: 0,0:00:24.00,0:00:28.00,Default,,0,0,0,,挖出最重要、最有料的那些資訊
Dialogue: 0,0:00:28.00,0:00:30.00,Default,,0,0,0,,千問三它到底厲害在哪裡
Dialogue: 0,0:00:30.00,0:00:33.00,Default,,0,0,0,,跟以前的模型有什麼不一樣
Dialogue: 0,0:00:33.00,0:00:36.00,Default,,0,0,0,,還有啊, 它那個聽起來很酷的思考模式
Dialogue: 0,0:00:36.00,0:00:40.00,Default,,0,0,0,,跟非思考模式到底是什麼東西
Dialogue: 0,0:00:40.00,0:00:41.00,Default,,0,0,0,,最重要的為什麼你
Dialogue: 0,0:00:41.00,0:00:43.00,Default,,0,0,0,,對, 就是正在聽的你
Dialogue: 0,0:00:43.00,0:00:46.00,Default,,0,0,0,,可能需要關心一下這個千問三
Dialogue: 0,0:00:46.00,0:00:49.00,Default,,0,0,0,,而且它這次不是只有一個模型
Dialogue: 0,0:00:49.00,0:00:52.00,Default,,0,0,0,,千問三是一個完整的家族系列
Dialogue: 0,0:00:52.00,0:00:54.00,Default,,0,0,0,,從比較輕巧的像是 0.6b
Dialogue: 0,0:00:54.00,0:00:57.00,Default,,0,0,0,,也就是十億參數的小模型
Dialogue: 0,0:00:57.00,0:01:01.00,Default,,0,0,0,,一直到超級大的 235b 參數的模型都有
Dialogue: 0,0:01:01.00,0:01:04.00,Default,,0,0,0,,這中間還包含了傳統的密集模型
Dialogue: 0,0:01:04.00,0:01:08.00,Default,,0,0,0,,還有那種更講求效率的專家混合模型
Dialogue: 0,0:01:08.00,0:01:09.00,Default,,0,0,0,,就是 Mowi
Dialogue: 0,0:01:09.00,0:01:11.00,Default,,0,0,0,,對, 而且還有一點很重要
Dialogue: 0,0:01:11.00,0:01:12.00,Default,,0,0,0,,對整個社羣來說
Dialogue: 0,0:01:12.00,0:01:15.00,Default,,0,0,0,,這次千問三的所有模型
Dialogue: 0,0:01:15.00,0:01:20.00,Default,,0,0,0,,注意哦, 是全部都用 Apache 2.0 這個社羣公開釋出了
Dialogue: 0,0:01:20.00,0:01:21.00,Default,,0,0,0,,這對於整個開源社羣
Dialogue: 0,0:01:21.00,0:01:24.00,Default,,0,0,0,,或是想自己動手做的開發者研究人員來說
Dialogue: 0,0:01:24.00,0:01:27.00,Default,,0,0,0,,真的是一個大禮包啊
Dialogue: 0,0:01:27.00,0:01:29.00,Default,,0,0,0,,沒錯沒錯, 開源就是讚
Dialogue: 0,0:01:29.00,0:01:31.00,Default,,0,0,0,,好, 那我們就不要浪費時間了
Dialogue: 0,0:01:31.00,0:01:33.00,Default,,0,0,0,,馬上來拆解這份報告
Dialogue: 0,0:01:33.00,0:01:37.00,Default,,0,0,0,,看看這個千問它的葫蘆裡到底賣的是什麼藥
Dialogue: 0,0:01:37.00,0:01:41.00,Default,,0,0,0,,好, 那我們就先從比較大的方向來看好了
Dialogue: 0,0:01:41.00,0:01:45.00,Default,,0,0,0,,這個千問三作為千問家族的最新一代碼
Dialogue: 0,0:01:45.00,0:01:47.00,Default,,0,0,0,,它想要解決的問題是什麼
Dialogue: 0,0:01:47.00,0:01:50.00,Default,,0,0,0,,或者說跟市面上那些很強的模型
Dialogue: 0,0:01:50.00,0:01:55.00,Default,,0,0,0,,比如 GPT-4O,Cloud 3.7,Gemini 2.5
Dialogue: 0,0:01:55.00,0:02:00.00,Default,,0,0,0,,這些相比千問三它想走出一條什麼樣不同的路
Dialogue: 0,0:02:00.00,0:02:01.00,Default,,0,0,0,,嗯, 這個問題很好
Dialogue: 0,0:02:01.00,0:02:04.00,Default,,0,0,0,,我覺得千問三的核心目標
Dialogue: 0,0:02:04.00,0:02:06.00,Default,,0,0,0,,是想在高性能、高效能
Dialogue: 0,0:02:06.00,0:02:10.00,Default,,0,0,0,,還有更強的多語言能力這三個方面找到一個
Dialogue: 0,0:02:10.00,0:02:12.00,Default,,0,0,0,,更好的平衡點
Dialogue: 0,0:02:12.00,0:02:14.00,Default,,0,0,0,,它不是只推一個模型就算了
Dialogue: 0,0:02:14.00,0:02:16.00,Default,,0,0,0,,而是推出一個完整的系列
Dialogue: 0,0:02:16.00,0:02:19.00,Default,,0,0,0,,從 0.6B 到 235B 參數都有
Dialogue: 0,0:02:19.00,0:02:21.00,Default,,0,0,0,,就是為了滿足不同的需求
Dialogue: 0,0:02:21.00,0:02:24.00,Default,,0,0,0,,其中啊, 那個 235B 的旗艦模型
Dialogue: 0,0:02:24.00,0:02:28.00,Default,,0,0,0,,Quan3,235B,AT2,AT2
Dialogue: 0,0:02:28.00,0:02:29.00,Default,,0,0,0,,就很有代表性
Dialogue: 0,0:02:29.00,0:02:31.00,Default,,0,0,0,,它是一個貿易模型
Dialogue: 0,0:02:31.00,0:02:34.00,Default,,0,0,0,,嗯, 專家混合模型
Dialogue: 0,0:02:34.00,0:02:36.00,Default,,0,0,0,,誒, 我們之前好像有聊過這個
Dialogue: 0,0:02:36.00,0:02:40.00,Default,,0,0,0,,簡單說就是模型裡面有很多專家
Dialogue: 0,0:02:40.00,0:02:42.00,Default,,0,0,0,,處理不同事情的時候
Dialogue: 0,0:02:42.00,0:02:45.00,Default,,0,0,0,,只會叫醒一部分相關的專家來工作
Dialogue: 0,0:02:45.00,0:02:46.00,Default,,0,0,0,,不是全部一起上工
Dialogue: 0,0:02:46.00,0:02:48.00,Default,,0,0,0,,所以會比較有效率
Dialogue: 0,0:02:48.00,0:02:48.00,Default,,0,0,0,,是這樣嗎?
Dialogue: 0,0:02:48.00,0:02:50.00,Default,,0,0,0,,對, 就是這個概念
Dialogue: 0,0:02:50.00,0:02:51.00,Default,,0,0,0,,你比得很好
Dialogue: 0,0:02:51.00,0:02:53.00,Default,,0,0,0,,這個 235B 的模型
Dialogue: 0,0:02:53.00,0:02:57.00,Default,,0,0,0,,它的總參數量有 2350 億這麼多
Dialogue: 0,0:02:57.00,0:02:59.00,Default,,0,0,0,,但是呢, 在實際運作的時候
Dialogue: 0,0:02:59.00,0:03:03.00,Default,,0,0,0,,大概只需要啟動裡面的 22 億參數
Dialogue: 0,0:03:03.00,0:03:04.00,Default,,0,0,0,,你可以想像成
Dialogue: 0,0:03:04.00,0:03:06.00,Default,,0,0,0,,一家超大的顧問公司
Dialogue: 0,0:03:06.00,0:03:09.00,Default,,0,0,0,,裡面有很多不同領域的頂尖專家
Dialogue: 0,0:03:09.00,0:03:10.00,Default,,0,0,0,,公司接到一個案子
Dialogue: 0,0:03:10.00,0:03:13.00,Default,,0,0,0,,不會叫全部的顧問都來開會
Dialogue: 0,0:03:13.00,0:03:16.00,Default,,0,0,0,,而是派出跟這個案子最相關的那幾個專家去處理
Dialogue: 0,0:03:16.00,0:03:16.00,Default,,0,0,0,,對不對?
Dialogue: 0,0:03:16.00,0:03:18.00,Default,,0,0,0,,嗯, 這個比喻我懂了
Dialogue: 0,0:03:18.00,0:03:21.00,Default,,0,0,0,,這樣一來, 既能維持服務的高品質
Dialogue: 0,0:03:21.00,0:03:23.00,Default,,0,0,0,,因為專家夠多嘛, 能力也強
Dialogue: 0,0:03:23.00,0:03:25.00,Default,,0,0,0,,同時又能控制營運成本
Dialogue: 0,0:03:25.00,0:03:27.00,Default,,0,0,0,,也就是運算的資源
Dialogue: 0,0:03:27.00,0:03:28.00,Default,,0,0,0,,了解
Dialogue: 0,0:03:28.00,0:03:30.00,Default,,0,0,0,,不過這次千文山還有一個
Dialogue: 0,0:03:30.00,0:03:32.00,Default,,0,0,0,,我覺得更吸引眼球的點
Dialogue: 0,0:03:32.00,0:03:35.00,Default,,0,0,0,,就是他們整合了所謂的思考模式
Dialogue: 0,0:03:35.00,0:03:37.00,Default,,0,0,0,,英文是 Thinking Mode
Dialogue: 0,0:03:37.00,0:03:39.00,Default,,0,0,0,,還有非思考模式
Dialogue: 0,0:03:39.00,0:03:40.00,Default,,0,0,0,,Non-Thinking Mode
Dialogue: 0,0:03:40.00,0:03:42.00,Default,,0,0,0,,這, 這到底是什麼?
Dialogue: 0,0:03:42.00,0:03:45.00,Default,,0,0,0,,聽起來好像模型會自己決定要不要認真想
Dialogue: 0,0:03:45.00,0:03:49.00,Default,,0,0,0,,這個的確是他們這次主打的一個
Dialogue: 0,0:03:49.00,0:03:50.00,Default,,0,0,0,,關鍵的創新點
Dialogue: 0,0:03:50.00,0:03:51.00,Default,,0,0,0,,以前是這樣
Dialogue: 0,0:03:51.00,0:03:54.00,Default,,0,0,0,,如果你想要模型能很快回答一些簡單問題
Dialogue: 0,0:03:54.00,0:03:56.00,Default,,0,0,0,,像聊天機器人那樣
Dialogue: 0,0:03:56.00,0:03:58.00,Default,,0,0,0,,你可能會選一個反應快的模型
Dialogue: 0,0:03:58.00,0:04:01.00,Default,,0,0,0,,但如果你要他解很複雜的數學題或者寫程式
Dialogue: 0,0:04:01.00,0:04:03.00,Default,,0,0,0,,需要深度推理的時候
Dialogue: 0,0:04:03.00,0:04:05.00,Default,,0,0,0,,你可能就得換另外一個更強
Dialogue: 0,0:04:05.00,0:04:07.00,Default,,0,0,0,,但可能又跑得比較慢的模型
Dialogue: 0,0:04:07.00,0:04:09.00,Default,,0,0,0,,千文山的野心就是
Dialogue: 0,0:04:09.00,0:04:11.00,Default,,0,0,0,,我們能不能在同一個模型裡面
Dialogue: 0,0:04:11.00,0:04:14.00,Default,,0,0,0,,就把這兩種需求都搞定
Dialogue: 0,0:04:14.00,0:04:16.00,Default,,0,0,0,,所以他會自己判斷任務
Dialogue: 0,0:04:16.00,0:04:17.00,Default,,0,0,0,,沒錯
Dialogue: 0,0:04:17.00,0:04:18.00,Default,,0,0,0,,報告裡面說
Dialogue: 0,0:04:18.00,0:04:20.00,Default,,0,0,0,,他可以根據你問問題的方式
Dialogue: 0,0:04:20.00,0:04:22.00,Default,,0,0,0,,或者是你給他的指令
Dialogue: 0,0:04:22.00,0:04:24.00,Default,,0,0,0,,比方說你用特定的模板去呼叫他
Dialogue: 0,0:04:24.00,0:04:26.00,Default,,0,0,0,,他就能自動切換模式
Dialogue: 0,0:04:26.00,0:04:28.00,Default,,0,0,0,,如果是需要快速反應
Dialogue: 0,0:04:28.00,0:04:29.00,Default,,0,0,0,,比較直接的任務
Dialogue: 0,0:04:29.00,0:04:32.00,Default,,0,0,0,,他就用非思考模式來處理
Dialogue: 0,0:04:32.00,0:04:34.00,Default,,0,0,0,,但如果遇到需要一步一步推敲
Dialogue: 0,0:04:34.00,0:04:35.00,Default,,0,0,0,,深度分析的任務
Dialogue: 0,0:04:35.00,0:04:36.00,Default,,0,0,0,,像是解難題
Dialogue: 0,0:04:36.00,0:04:38.00,Default,,0,0,0,,他就會切換到思考模式
Dialogue: 0,0:04:38.00,0:04:40.00,Default,,0,0,0,,投入更多的運算資源
Dialogue: 0,0:04:40.00,0:04:41.00,Default,,0,0,0,,去想清楚
Dialogue: 0,0:04:41.00,0:04:43.00,Default,,0,0,0,,誒, 這個比喻不錯
Dialogue: 0,0:04:43.00,0:04:44.00,Default,,0,0,0,,像開車換擋
Dialogue: 0,0:04:44.00,0:04:46.00,Default,,0,0,0,,對對, 有點像開車
Dialogue: 0,0:04:46.00,0:04:47.00,Default,,0,0,0,,在市區順順開用一個檔位
Dialogue: 0,0:04:47.00,0:04:49.00,Default,,0,0,0,,遇到要爬陡坡
Dialogue: 0,0:04:49.00,0:04:50.00,Default,,0,0,0,,需要更多馬力的時候
Dialogue: 0,0:04:50.00,0:04:51.00,Default,,0,0,0,,你就換個檔
Dialogue: 0,0:04:51.00,0:04:52.00,Default,,0,0,0,,大概是這種感覺
Dialogue: 0,0:04:52.00,0:04:55.00,Default,,0,0,0,,哇, 那這樣聽起來真的方便很多
Dialogue: 0,0:04:55.00,0:04:57.00,Default,,0,0,0,,以後就不用為了不同的任務
Dialogue: 0,0:04:57.00,0:05:00.00,Default,,0,0,0,,傷腦筋說要換哪個模型了
Dialogue: 0,0:05:00.00,0:05:03.00,Default,,0,0,0,,報告裡還提到一個詞叫做思考預算
Dialogue: 0,0:05:03.00,0:05:05.00,Default,,0,0,0,,Thinking Budget
Dialogue: 0,0:05:05.00,0:05:06.00,Default,,0,0,0,,這意思是說
Dialogue: 0,0:05:06.00,0:05:09.00,Default,,0,0,0,,我還可以控制他思考的程度嗎
Dialogue: 0,0:05:09.00,0:05:12.00,Default,,0,0,0,,好像在給他零用錢一樣
Dialogue: 0,0:05:12.00,0:05:14.00,Default,,0,0,0,,有點那個意思
Dialogue: 0,0:05:14.00,0:05:17.00,Default,,0,0,0,,這就提供了更細緻的控制權
Dialogue: 0,0:05:17.00,0:05:18.00,Default,,0,0,0,,你可以指定說
Dialogue: 0,0:05:18.00,0:05:22.00,Default,,0,0,0,,這次任務要分配多少運算資源
Dialogue: 0,0:05:22.00,0:05:24.00,Default,,0,0,0,,通常是用 Token 的數量來算
Dialogue: 0,0:05:24.00,0:05:26.00,Default,,0,0,0,,給思考這個過程
Dialogue: 0,0:05:26.00,0:05:28.00,Default,,0,0,0,,如果任務超級複雜
Dialogue: 0,0:05:28.00,0:05:34.00,Default,,0,0,0,,你可以給多一點預算, 讓他想得更周全一點, 但可能回應速度就會慢一些。
Dialogue: 0,0:05:34.00,0:05:40.00,Default,,0,0,0,,那如果任務相對簡單, 或者你更在意反應速度, 那你就可以給少一點預算。
Dialogue: 0,0:05:40.00,0:05:41.00,Default,,0,0,0,,嗯。
Dialogue: 0,0:05:41.00,0:05:47.00,Default,,0,0,0,,這就讓使用者可以在回應速度, 也就是延遲, 和答案的品質之間, 自己做一個取捨。
Dialogue: 0,0:05:47.00,0:05:51.00,Default,,0,0,0,,這個設計真的蠻有意思的, 感覺彈性大很多。
Dialogue: 0,0:05:51.00,0:05:57.00,Default,,0,0,0,,除了這個思考模式, 多語言能力也是這次千問三的一大亮點。
Dialogue: 0,0:05:57.00,0:06:08.00,Default,,0,0,0,,報告說, 從上一代千問 2.5 支援的 29 種語言, 這次一口氣增加到支援 119 種語言和方言。
Dialogue: 0,0:06:08.00,0:06:10.00,Default,,0,0,0,,這個跨度很大耶。
Dialogue: 0,0:06:10.00,0:06:11.00,Default,,0,0,0,,非常大, 對。
Dialogue: 0,0:06:11.00,0:06:15.00,Default,,0,0,0,,這背後其實就是靠著龐大的預訓練資料在支撐。
Dialogue: 0,0:06:15.00,0:06:20.00,Default,,0,0,0,,總共用了高達 36 兆, 吃臉, 這麼多的 Token。
Dialogue: 0,0:06:20.00,0:06:31.00,Default,,0,0,0,,能夠支援這麼多語言, 你想想看, 對於那些需要服務全球用戶的應用程式, 或者需要做跨語言分析的研究任務來說, 這個潛力就大很多了。
Dialogue: 0,0:06:31.00,0:06:32.00,Default,,0,0,0,,對啊。
Dialogue: 0,0:06:32.00,0:06:41.00,Default,,0,0,0,,從主流語言到一些可能比較少見的方言, 模型都能有一定程度的理解和生成能力, 這確實是往前邁進了一大步。
Dialogue: 0,0:06:41.00,0:06:46.00,Default,,0,0,0,,那我們接下來就來看看, 這麼厲害的模型, 它到底是怎麼練出來的。
Dialogue: 0,0:06:46.00,0:06:51.00,Default,,0,0,0,,首先最重要的, 當然是它的食材, 也就是預訓練的資料。
Dialogue: 0,0:06:51.00,0:06:58.00,Default,,0,0,0,,剛剛提到了嘛, 規模達到了驚人的 36 兆 Token, 而且橫跨了 119 種語言。
Dialogue: 0,0:06:58.00,0:07:04.00,Default,,0,0,0,,但我覺得更有趣的是, 他們收集資料的方式有一些, 嗯, 蠻聰明的做法。
Dialogue: 0,0:07:04.00,0:07:08.00,Default,,0,0,0,,哦, 有什麼特別的嗎? 聽起來不只是爬網路資料而已。
Dialogue: 0,0:07:09.00,0:07:16.00,Default,,0,0,0,,對, 不只。他們除了用傳統的網頁資料收集這些, 還用了一些 AI 幫 AI 的方式。
Dialogue: 0,0:07:16.00,0:07:26.00,Default,,0,0,0,,比方說, 他們用了自家的視覺語言模型, 就是千問 2.5VL, 去讀取大量的 PDF 文件, 然後把裡面的文字內容給提取出來。
Dialogue: 0,0:07:26.00,0:07:29.00,Default,,0,0,0,,哇, 用 AI 讀 PDF。
Dialogue: 0,0:07:29.00,0:07:45.00,Default,,0,0,0,,對, 還有喔, 他們還用了專門處理數學問題的千問 2.5-Math, 和專門處理程式碼的千問 2.5-Coder, 去生成更多更高品質的數學和程式碼相關的訓練資料。
Dialogue: 0,0:07:45.00,0:07:57.00,Default,,0,0,0,,等等, 用 AI 模型來生成訓練資料, 然後再用這些資料去訓練新的 AI 模型, 這聽起來像是一個自我進化的循環, 蠻酷的。
Dialogue: 0,0:07:57.00,0:08:05.00,Default,,0,0,0,,的確是這樣, 這個做法現在也越來越常見了, 用模型來產生合成資料, 補充訓練數據。
Dialogue: 0,0:08:05.00,0:08:13.00,Default,,0,0,0,,好, 那有了這些豐富的食材之後, 實際的訓練過程呢? 報告裡有提到, 他們用了一個三階段的策略。
Dialogue: 0,0:08:13.00,0:08:19.00,Default,,0,0,0,,嗯, 三階段策略, 可以想像成是模型的成長三部曲嗎?
Dialogue: 0,0:08:20.00,0:08:28.00,Default,,0,0,0,,可以這樣說, 這個養成計畫是這樣的, 第一階段叫做打基礎, 也就是通用階段 S1。
Dialogue: 0,0:08:28.00,0:08:35.00,Default,,0,0,0,,這個階段用了最多的資料, 超過 30 兆 Token, 涵蓋了全部 119 種語言。
Dialogue: 0,0:08:35.00,0:08:42.00,Default,,0,0,0,,目標是讓所有的千問 3 模型, 先建立起廣泛的世界知識和基本的語言理解能力。
Dialogue: 0,0:08:42.00,0:08:48.00,Default,,0,0,0,,這時候模型的視野, 也就是序列長度, 是 4096 個 Token。
Dialogue: 0,0:08:48.00,0:08:50.00,Default,,0,0,0,,嗯, 先把基礎打好。
Dialogue: 0,0:08:50.00,0:08:56.00,Default,,0,0,0,,對, 接下來是第二階段, 練腦力, 也就是推理階段 S2。
Dialogue: 0,0:08:56.00,0:09:09.00,Default,,0,0,0,,為了強化模型解決複雜問題的能力, 像是數理邏輯、寫程式這些, 他們調整了訓練資料的配方, 增加了 STEM 領域、程式碼還有推理相關內容的比例。
Dialogue: 0,0:09:09.00,0:09:18.00,Default,,0,0,0,,這裡面也包含了剛剛提到的 AI 合成資料, 然後再用大概 5 兆左右品質更高的 Token 進行精修。
Dialogue: 0,0:09:18.00,0:09:29.00,Default,,0,0,0,,同時, 他們也加快了學習率衰減的速度, 有點像是進入學習的衝刺期。序列長度在這個階段還是維持在 4096。
Dialogue: 0,0:09:29.00,0:09:31.00,Default,,0,0,0,,好, 練完腦力之後呢?
Dialogue: 0,0:09:31.00,0:09:35.00,Default,,0,0,0,,第三階段就是增廣見聞, 長文階段。
Dialogue: 0,0:09:35.00,0:09:41.00,Default,,0,0,0,,這個階段的目的是讓模型能夠處理更長的資訊, 看懂長篇文章。
Dialogue: 0,0:09:41.00,0:09:53.00,Default,,0,0,0,,他們特別收集了高品質的長篇文件資料, 把模型的上下文處理能力從 4096Token 大幅擴展到 32768Token。
Dialogue: 0,0:09:53.00,0:10:03.00,Default,,0,0,0,,而且, 為了讓模型在實際使用, 也就是推理的時候能夠看得更遠, 報告提到有些模型甚至可以處理到 128KToken。
Dialogue: 0,0:10:03.00,0:10:14.00,Default,,0,0,0,,他們用了一些特別的技術, 像是調整 Rope 位置編碼的頻率, 這個技術叫做 ABF, 還有像是 Yarn 和雙區塊注意力,DCA。
Dialogue: 0,0:10:14.00,0:10:16.00,Default,,0,0,0,,哇, 聽起來很有條理。
Dialogue: 0,0:10:16.00,0:10:25.00,Default,,0,0,0,,先學會基本的聽說讀寫, 然後集中火力加強數理邏輯, 最後再鍛鍊處理長篇大論的能力。
Dialogue: 0,0:10:25.00,0:10:29.00,Default,,0,0,0,,那模型本身的骨架也就是它的架構設計呢?
Dialogue: 0,0:10:29.00,0:10:36.00,Default,,0,0,0,,剛剛有提到分密集模型和某一模型, 他們在設計上有什麼不一樣的地方嗎?
Dialogue: 0,0:10:36.00,0:10:49.00,Default,,0,0,0,,密集模型, 就是從 0.6B 到 32B 參數的那些, 基本上採用了目前業界比較成熟, 驗證過有效的技術組合。
Dialogue: 0,0:10:50.00,0:10:56.00,Default,,0,0,0,,像是用 Group Query Attention, GQA, 來提升注意力機制的效率
Dialogue: 0,0:10:56.00,0:10:59.00,Default,,0,0,0,,用 SweetGlue 作為活化函數
Dialogue: 0,0:10:59.00,0:11:04.00,Default,,0,0,0,,還有 Rope 位置編碼,RMS Norm 正規化等等
Dialogue: 0,0:11:04.00,0:11:07.00,Default,,0,0,0,,不過他們也做了一些自己的調整
Dialogue: 0,0:11:07.00,0:11:11.00,Default,,0,0,0,,比方說加入了一個叫做 QKNorm 的東西
Dialogue: 0,0:11:11.00,0:11:14.00,Default,,0,0,0,,據說是為了提升訓練的穩定性
Dialogue: 0,0:11:14.00,0:11:20.00,Default,,0,0,0,,還有, 他們拿掉了上一代千問二模型裡面的 QKV 編制項
Dialogue: 0,0:11:20.00,0:11:23.00,Default,,0,0,0,,嗯哼, 那 MoE 模型呢?
Dialogue: 0,0:11:23.00,0:11:27.00,Default,,0,0,0,,MoE 模型就是那個 30B 啟用 3B 參數的
Dialogue: 0,0:11:27.00,0:11:32.00,Default,,0,0,0,,還有旗艦級 235B 啟用 22B 參數的這兩款
Dialogue: 0,0:11:32.00,0:11:36.00,Default,,0,0,0,,他們是在密集模型的基礎架構上搭建的
Dialogue: 0,0:11:36.00,0:11:38.00,Default,,0,0,0,,他們用了更細緻的專家切分
Dialogue: 0,0:11:38.00,0:11:41.00,Default,,0,0,0,,總共有 128 位專家這麼多
Dialogue: 0,0:11:41.00,0:11:45.00,Default,,0,0,0,,然後每次運作的時候會啟用其中的 8 位
Dialogue: 0,0:11:45.00,0:11:47.00,Default,,0,0,0,,一個值得注意的改變是
Dialogue: 0,0:11:47.00,0:11:52.00,Default,,0,0,0,,這次千問三的 MoE 模型沒有使用所謂的共享專家
Dialogue: 0,0:11:52.00,0:11:54.00,Default,,0,0,0,,誒? 沒有共享專家?
Dialogue: 0,0:11:54.00,0:11:56.00,Default,,0,0,0,,這是什麼意思? 跟以前有什麼不同?
Dialogue: 0,0:11:56.00,0:12:01.00,Default,,0,0,0,,以前有些 MoE 的設計會有一些通材型的專家
Dialogue: 0,0:12:01.00,0:12:04.00,Default,,0,0,0,,就是不管什麼任務可能都會用到他們
Dialogue: 0,0:12:04.00,0:12:06.00,Default,,0,0,0,,千問三這次沒有共享專家
Dialogue: 0,0:12:06.00,0:12:09.00,Default,,0,0,0,,我的理解是他們可能希望每一位專家
Dialogue: 0,0:12:09.00,0:12:12.00,Default,,0,0,0,,都能更專注在自己的特定領域
Dialogue: 0,0:12:12.00,0:12:15.00,Default,,0,0,0,,變得更專精而不是什麼都會一點
Dialogue: 0,0:12:15.00,0:12:17.00,Default,,0,0,0,,另外他們還採用了一種叫做
Dialogue: 0,0:12:17.00,0:12:21.00,Default,,0,0,0,,全局批次負載平衡損失的機制
Dialogue: 0,0:12:21.00,0:12:23.00,Default,,0,0,0,,這個聽起來有點專業
Dialogue: 0,0:12:23.00,0:12:24.00,Default,,0,0,0,,目的是什麼?
Dialogue: 0,0:12:24.00,0:12:27.00,Default,,0,0,0,,這個機制的目的是確保在訓練過程中
Dialogue: 0,0:12:27.00,0:12:33.00,Default,,0,0,0,,分配給所有 128 位專家的工作量能夠盡量平均
Dialogue: 0,0:12:33.00,0:12:36.00,Default,,0,0,0,,避免出現有些專家閒閒沒事做
Dialogue: 0,0:12:36.00,0:12:38.00,Default,,0,0,0,,有些專家卻忙不過來的狀況
Dialogue: 0,0:12:38.00,0:12:42.00,Default,,0,0,0,,這樣也能鼓勵專家們各自發展出獨特的專長
Dialogue: 0,0:12:42.00,0:12:44.00,Default,,0,0,0,,最終的目標
Dialogue: 0,0:12:44.00,0:12:47.00,Default,,0,0,0,,都是為了提升模型的整體效能和效率
Dialogue: 0,0:12:47.00,0:12:51.00,Default,,0,0,0,,原來是為了讓專家們分工更明確更有效率
Dialogue: 0,0:12:51.00,0:12:53.00,Default,,0,0,0,,對
Dialogue: 0,0:12:53.00,0:12:54.00,Default,,0,0,0,,還有一個小細節
Dialogue: 0,0:12:54.00,0:12:56.00,Default,,0,0,0,,所有這些模型
Dialogue: 0,0:12:56.00,0:12:59.00,Default,,0,0,0,,不管大小是密集還是 MoE
Dialogue: 0,0:12:59.00,0:13:02.00,Default,,0,0,0,,都用的是同一個 Tokenizer
Dialogue: 0,0:13:02.00,0:13:03.00,Default,,0,0,0,,也就是分詞器
Dialogue: 0,0:13:03.00,0:13:07.00,Default,,0,0,0,,它是基於 BBPE 演算法的
Dialogue: 0,0:13:07.00,0:13:09.00,Default,,0,0,0,,詞彙量有 15 萬多
Dialogue: 0,0:13:09.00,0:13:11.00,Default,,0,0,0,,15 萬 1669
Dialogue: 0,0:13:11.00,0:13:13.00,Default,,0,0,0,,這個比較大的詞彙量
Dialogue: 0,0:13:13.00,0:13:16.00,Default,,0,0,0,,也有助於它處理多樣的語言
Dialogue: 0,0:13:16.00,0:13:17.00,Default,,0,0,0,,還有一些特殊的符號
Dialogue: 0,0:13:17.00,0:13:18.00,Default,,0,0,0,,了解了
Dialogue: 0,0:13:18.00,0:13:20.00,Default,,0,0,0,,所以 MoE 的設計
Dialogue: 0,0:13:20.00,0:13:24.00,Default,,0,0,0,,更強調讓每個專家術業有專攻
Dialogue: 0,0:13:24.00,0:13:29.00,Default,,0,0,0,,那報告裡提到模型上下文長度最高可以到 12K Token
Dialogue: 0,0:13:29.00,0:13:31.00,Default,,0,0,0,,哇 這真的很厲害
Dialogue: 0,0:13:31.00,0:13:35.00,Default,,0,0,0,,代表模型可以一次看懂非常非常長的文件
Dialogue: 0,0:13:35.00,0:13:37.00,Default,,0,0,0,,或對話紀錄了
Dialogue: 0,0:13:37.00,0:13:39.00,Default,,0,0,0,,好 模型練出來了
Dialogue: 0,0:13:39.00,0:13:42.00,Default,,0,0,0,,總是要看看功夫練得怎麼樣嘛
Dialogue: 0,0:13:42.00,0:13:46.00,Default,,0,0,0,,報告接下來就比較了這些基礎模型的表現
Dialogue: 0,0:13:46.00,0:13:48.00,Default,,0,0,0,,誒 這邊要強調一下喔
Dialogue: 0,0:13:48.00,0:13:49.00,Default,,0,0,0,,是基礎模型喔
Dialogue: 0,0:13:49.00,0:13:51.00,Default,,0,0,0,,也就是剛預訓練完
Dialogue: 0,0:13:51.00,0:13:56.00,Default,,0,0,0,,還沒有針對聊天或指令遵循做特別優化的版本
Dialogue: 0,0:13:56.00,0:14:00.00,Default,,0,0,0,,他們把千問 3 跟上一代的千問 2.5
Dialogue: 0,0:14:00.00,0:14:02.00,Default,,0,0,0,,還有像 DeepSeek V3
Dialogue: 0,0:14:02.00,0:14:03.00,Default,,0,0,0,,Llama 系列
Dialogue: 0,0:14:03.00,0:14:04.00,Default,,0,0,0,,Jammer 系列
Dialogue: 0,0:14:04.00,0:14:08.00,Default,,0,0,0,,這些市面上的對手放在一起做了很多比較
Dialogue: 0,0:14:08.00,0:14:09.00,Default,,0,0,0,,結果怎麼樣
Dialogue: 0,0:14:09.00,0:14:11.00,Default,,0,0,0,,有沒有讓人覺得哇的發現
Dialogue: 0,0:14:11.00,0:14:15.00,Default,,0,0,0,,基礎模型的評測結果確實
Dialogue: 0,0:14:15.00,0:14:17.00,Default,,0,0,0,,給人一個很強烈的印象
Dialogue: 0,0:14:17.00,0:14:19.00,Default,,0,0,0,,就是效率大幅提升
Dialogue: 0,0:14:19.00,0:14:23.00,Default,,0,0,0,,千問 3 的模型常常可以用比較小的參數規模
Dialogue: 0,0:14:23.00,0:14:27.00,Default,,0,0,0,,達到甚至超越參數規模大很多的對手
Dialogue: 0,0:14:27.00,0:14:30.00,Default,,0,0,0,,或者是自家的前一代模型
Dialogue: 0,0:14:30.00,0:14:34.00,Default,,0,0,0,,好 有用小博大的感覺嗎
Dialogue: 0,0:14:34.00,0:14:35.00,Default,,0,0,0,,可以舉幾個例子來聽聽嗎
Dialogue: 0,0:14:35.00,0:14:36.00,Default,,0,0,0,,當然
Dialogue: 0,0:14:36.00,0:14:39.00,Default,,0,0,0,,比如他們那個最大的貿易模型
Dialogue: 0,0:14:39.00,0:14:43.00,Default,,0,0,0,,QN3-235B-R2B-Base
Dialogue: 0,0:14:43.00,0:14:45.00,Default,,0,0,0,,報告裡面宣稱喔
Dialogue: 0,0:14:45.00,0:14:47.00,Default,,0,0,0,,在大多數的評測項目上
Dialogue: 0,0:14:47.00,0:14:51.00,Default,,0,0,0,,它的表現比 DeepSeek V3 Base 這個模型要好
Dialogue: 0,0:14:51.00,0:14:55.00,Default,,0,0,0,,但重點是千問 3 這個模型的總參數量
Dialogue: 0,0:14:55.00,0:14:57.00,Default,,0,0,0,,只有對方的大約三分之一
Dialogue: 0,0:14:57.00,0:15:01.00,Default,,0,0,0,,實際啟用的參數也只有對方的大約三分之二
Dialogue: 0,0:15:01.00,0:15:04.00,Default,,0,0,0,,哇 參數少這麼多 表現還更好
Dialogue: 0,0:15:04.00,0:15:08.00,Default,,0,0,0,,對 然後跟 Llama 4 Maverick Base 這個模型比
Dialogue: 0,0:15:08.00,0:15:11.00,Default,,0,0,0,,千問 3 的總參數也只有對方的一半左右
Dialogue: 0,0:15:11.00,0:15:13.00,Default,,0,0,0,,這就顯示出喔
Dialogue: 0,0:15:13.00,0:15:16.00,Default,,0,0,0,,他們這次新的架構和訓練方法
Dialogue: 0,0:15:16.00,0:15:18.00,Default,,0,0,0,,確實帶來了實質進步
Dialogue: 0,0:15:18.00,0:15:20.00,Default,,0,0,0,,它也明顯比自家的上一代
Dialogue: 0,0:15:20.00,0:15:25.00,Default,,0,0,0,,QN2.5 Plus 和 72B Base 要強很多
Dialogue: 0,0:15:25.00,0:15:28.00,Default,,0,0,0,,還有一個我覺得更驚人的是
Dialogue: 0,0:15:28.00,0:15:31.00,Default,,0,0,0,,QN3 32B Base
Dialogue: 0,0:15:31.00,0:15:33.00,Default,,0,0,0,,這是他們最大的密集模型
Dialogue: 0,0:15:33.00,0:15:34.00,Default,,0,0,0,,不是貿易喔
Dialogue: 0,0:15:34.00,0:15:36.00,Default,,0,0,0,,它的表現非常有競爭力
Dialogue: 0,0:15:36.00,0:15:38.00,Default,,0,0,0,,報告裡面提到
Dialogue: 0,0:15:38.00,0:15:41.00,Default,,0,0,0,,在他們比較的十五個評測項目裡面
Dialogue: 0,0:15:41.00,0:15:42.00,Default,,0,0,0,,有十個項目
Dialogue: 0,0:15:42.00,0:15:44.00,Default,,0,0,0,,這個 32B 的模型
Dialogue: 0,0:15:44.00,0:15:47.00,Default,,0,0,0,,居然贏過了參數是它兩倍多的
Dialogue: 0,0:15:47.00,0:15:49.00,Default,,0,0,0,,自家的前一代
Dialogue: 0,0:15:49.00,0:15:53.00,Default,,0,0,0,,QN2.5 72B Base
Dialogue: 0,0:15:53.00,0:15:54.00,Default,,0,0,0,,等等
Dialogue: 0,0:15:54.00,0:15:58.00,Default,,0,0,0,,32B 打贏了 72B
Dialogue: 0,0:15:58.00,0:16:01.00,Default,,0,0,0,,這差距有點大耶
Dialogue: 0,0:16:01.00,0:16:04.00,Default,,0,0,0,,這是不是意味著他們在訓練方法
Dialogue: 0,0:16:04.00,0:16:05.00,Default,,0,0,0,,或者架構上
Dialogue: 0,0:16:05.00,0:16:08.00,Default,,0,0,0,,真的找到了什麼關鍵的訣竅
Dialogue: 0,0:16:08.00,0:16:11.00,Default,,0,0,0,,讓參數的利用效率變得非常非常高
Dialogue: 0,0:16:11.00,0:16:13.00,Default,,0,0,0,,這確實是很可能的
Dialogue: 0,0:16:13.00,0:16:16.00,Default,,0,0,0,,報告雖然沒有把所有祕方都公開
Dialogue: 0,0:16:16.00,0:16:18.00,Default,,0,0,0,,但我們前面提到的第二階段
Dialogue: 0,0:16:18.00,0:16:30.00,Default,,0,0,0,,這個針對推理能力的講話訓練, 還有架構上的一些微調, 像是用了 QKNORM, 拿掉 QKB 編制這些, 可能都對提升參數效率有不小的貢獻。
Dialogue: 0,0:16:30.00,0:16:45.00,Default,,0,0,0,,而且這個趨勢也延續到其他模型上, 像是 QN3 14B-BASE, 這個密集模型, 還有 QN3 30B AA 3B-BASE, 這個 MoE 模型, 它啟用的是 3B 參數。
Dialogue: 0,0:16:45.00,0:17:06.00,Default,,0,0,0,,那個 14B 的密集模型基本上打敗了同級的其他對手, 甚至可以跟上一代的 QN2.5 32B 把個平手, 而那個 30B 的 MoE 模型呢, 雖然總參數量有 300 億, 但實際運作只需要啟用 30 億參數, 就能達到跟 14B 密集模型差不多的性能。
Dialogue: 0,0:17:07.00,0:17:16.00,Default,,0,0,0,,這就再次凸顯了 MoE 在效率上的優勢, 用更少的實際運算量, 就能達到接近更大密集模型的表現。
Dialogue: 0,0:17:16.00,0:17:21.00,Default,,0,0,0,,這對於那些運算資源比較有限的使用者來說, 真的是個好消息。
Dialogue: 0,0:17:21.00,0:17:27.00,Default,,0,0,0,,那更小的模型呢? 比如 8B、4B 這些常用的尺寸?
Dialogue: 0,0:17:27.00,0:17:47.00,Default,,0,0,0,,這些小型模型的表現同樣是相當亮眼, 報告裡的數據顯示, 它們常常能夠超越前一代, 甚至更大規模的 QN2.5 模型, 特別是在 STEM 和程式碼相關的基準測試上, 這表示 QN3 這次的進步是全系列的, 不是只有大模型變強而已。
Dialogue: 0,0:17:47.00,0:18:10.00,Default,,0,0,0,,所以, 聽起來一個很重要反覆出現的結論, 就是 QN3 在基礎能力上實現了非常顯著的代際提升, 可以用更少的參數, 做到跟以前更大模型相當, 甚至更好的事情, 尤其是在寫程式和數理推理這些方面, 而且 MoE 架構的效率優勢也再次得到驗證。
Dialogue: 0,0:18:10.00,0:18:28.00,Default,,0,0,0,,沒錯, 預訓練把模型的基礎能力打好了, 但是要讓模型真正好用, 能夠聽懂人話, 遵循指令, 甚至具備解決複雜問題的推理能力, 那還需要經過後訓練,Post-training 這個階段來進行精密的調教。
Dialogue: 0,0:18:28.00,0:18:54.00,Default,,0,0,0,,QN3 的後訓練主要有兩大核心目標, 第一, 就是要實現我們前面一直提到的那個思考控制機制, 包括思考模式和非思考模式之間的切換, 還有思考預算的控制。第二個目標, 是針對那些比較小的模型, 用一種叫做強者對弱者爭留的技術, 來更有效率的訓練他們。
Dialogue: 0,0:18:54.00,0:19:07.00,Default,,0,0,0,,好, 那我們先來看看那個最複雜的旗艦模型, 報告裡好像有個圖, 圖一, 展示了他的一個四階段後訓練流程, 這四個階段分別是在做什麼? 聽起來就很講究。
Dialogue: 0,0:19:07.00,0:19:36.00,Default,,0,0,0,,嗯, 這個四階段流程確實是為了打造出頂尖的推理能力, 並且讓模式切換做得很好。第一階段, 他們叫做長思路鏈冷啟動,Long-Caught Cold-Start, 這個階段有點像是要先幫模型開竅, 教會它怎麼一步一步思考, 他們用了一個精挑細選過的資料集, 裡面都是那種需要多步驟思考, 也就是思路鏈,Chain of Thought, 才能解決的複雜問題。
Dialogue: 0,0:19:36.00,0:20:06.00,Default,,0,0,0,,涵蓋了數學、程式碼、邏輯推理等等。而且, 很重要的一點是, 這些問題都有經過驗證的標準答案或是明確的測試方法。他們在報告裡強調, 這個階段非常注重資料品質, 透過很嚴格的篩選, 確保模型學到的是真正深度推理的模式, 而不是死記硬背一些答案。目標不是追求立刻得到高分, 而是先植入正確的思考習慣。
Dialogue: 0,0:20:06.00,0:20:08.00,Default,,0,0,0,,嗯, 先打好思考的基礎。
Dialogue: 0,0:20:08.00,0:20:31.00,Default,,0,0,0,,對, 有了基礎之後, 跌的階段就要強化推理能力,Reasoning RL。這時候就用上了強化學習,Reinforcement Learning。具體來說, 他們用的是一種叫做 GRPO 的演算法, 在一些特別有挑戰性而且能夠明確判斷答案對錯的問題驗證器配對上進行訓練。
Dialogue: 0,0:20:31.00,0:20:45.00,Default,,0,0,0,,強化學習的概念簡單說, 就是讓模型自己去嘗試回答問題, 答對了就給他獎勵, 答錯了就給他一點懲罰。透過這樣不斷的嘗試和回饋, 讓他自己摸索出更好的解題策略。
Dialogue: 0,0:20:45.00,0:20:47.00,Default,,0,0,0,,像是在玩遊戲練功一樣。
Dialogue: 0,0:20:47.00,0:21:06.00,Default,,0,0,0,,有點像。報告裡舉了一個例子, 他們最大的那個 MOE Model, 在一個叫做 AMME24 的數學競賽基準測試上, 經過了 170 次強化學習步驟之後, 分數從原本的 70.1 大幅提升到了 85.1。
Dialogue: 0,0:21:06.00,0:21:08.00,Default,,0,0,0,,哇, 提升這麼多。
Dialogue: 0,0:21:08.00,0:21:15.00,Default,,0,0,0,,對, 這顯示強化學習對於提升高難度推理能力, 效果是非常顯著的。
Dialogue: 0,0:21:15.00,0:21:19.00,Default,,0,0,0,,好, 那前兩階段都在練思考, 接下來呢?
Dialogue: 0,0:21:19.00,0:21:23.00,Default,,0,0,0,,第三階段, 叫做思考模式融合。
Dialogue: 0,0:21:23.00,0:21:32.00,Default,,0,0,0,,這個階段的目標, 是把非思考的能力也整合進來, 並且教會模型如何在這兩種模式之間切換。
Dialogue: 0,0:21:32.00,0:21:37.00,Default,,0,0,0,,他們用的是監督式微調,Supervised Fine Tuning,SFT。
Dialogue: 0,0:21:37.00,0:21:46.00,Default,,0,0,0,,訓練資料裡面既包含了需要思考的內容, 主要是來自階段二模型產生的那些優質的帶有思考過程的東西。
Dialogue: 0,0:21:46.00,0:21:55.00,Default,,0,0,0,,也包含了大量不需要思考的任務資料, 像是快速問答, 遵循簡單指令, 創意寫作, 多語言翻譯等等。
Dialogue: 0,0:21:55.00,0:22:05.00,Default,,0,0,0,,最關鍵的是, 他們在這個階段引入了帶有 Think 和 No Think 這種特殊標籤的聊天模板, 報告的表 9 有給出範例。
Dialogue: 0,0:22:05.00,0:22:15.00,Default,,0,0,0,,這等於是明確地告訴模型, 誒, 看到這種指令, 你就要啟動思考模式, 看到那種指令, 就用非思考模式快速回應。
Dialogue: 0,0:22:15.00,0:22:18.00,Default,,0,0,0,,哦, 用標籤來教他切換。
Dialogue: 0,0:22:18.00,0:22:29.00,Default,,0,0,0,,對, 而且有趣的是, 報告提到, 模型在這個階段的訓練過程中, 也自然而然地學會了根據你給的思考預算來調整思考深度的能力。
Dialogue: 0,0:22:29.00,0:22:31.00,Default,,0,0,0,,嗯哼, 那第四階段呢?
Dialogue: 0,0:22:31.00,0:22:36.00,Default,,0,0,0,,最後的第四階段是通用強化學習,General RL。
Dialogue: 0,0:22:36.00,0:22:45.00,Default,,0,0,0,,這個階段的目標是讓模型在各種實際的應用場景中表現得更好、更穩定、更符合人類的期望。
Dialogue: 0,0:22:45.00,0:22:48.00,Default,,0,0,0,,不只是推理能力, 還包括很多方面。
Dialogue: 0,0:22:48.00,0:23:00.00,Default,,0,0,0,,能不能準確理解並且遵循複雜的指令, 能不能按照你要求的格式來輸出答案, 回答的內容是不是安全, 沒有偏見, 符合人類的偏好,
Dialogue: 0,0:23:00.00,0:23:12.00,Default,,0,0,0,,能不能像一個智慧助理一樣去使用外部的工具來完成任務, 也就是 Agent 的能力, 能不能在 RAG, 就是檢索增強生成這類場景下表現良好。
Dialogue: 0,0:23:12.00,0:23:16.00,Default,,0,0,0,,為了達到這些目標, 他們用了一個非常複雜的獎勵系統。
Dialogue: 0,0:23:16.00,0:23:29.00,Default,,0,0,0,,這個系統綜合了規則判斷跟標準答案比對的結果, 甚至在沒有標準答案的情況下, 讓其他的 AI 模型來對他的回答進行評分, 從各個角度來給予模型全面的回饋, 引導他變得更完善。
Dialogue: 0,0:23:29.00,0:23:36.00,Default,,0,0,0,,哇, 這四個階段聽起來工程真的超浩大, 而且環環相扣耶!
Dialogue: 0,0:23:36.00,0:23:50.00,Default,,0,0,0,,先教思考方法, 再用強化學習加強思考能力, 然後把思考和不思考兩種模式融合起來並學會切換, 最後再進行全面的打磨讓它更實用。
Dialogue: 0,0:23:50.00,0:23:58.00,Default,,0,0,0,,那對於那些比較小的模型呢? 他們也要經歷這麼複雜的過程嗎? 你剛好像有提到用蒸餾。
Dialogue: 0,0:23:58.00,0:24:13.00,Default,,0,0,0,,對, 沒錯, 對於 0.6B 到 14B 的那些密集模型, 還有那個 30B 的貓翼模型, 如果要讓他們也完整的走一遍這四階段的強化學習流程, 那計算成本實在太高了。
Dialogue: 0,0:24:13.00,0:24:19.00,Default,,0,0,0,,所以, 研究團隊為他們設計了一條捷徑, 就是用強者對弱者蒸餾。
Dialogue: 0,0:24:19.00,0:24:35.00,Default,,0,0,0,,這個方法的核心思想很直觀, 就是讓一個已經訓練好的、更強大的教師模型, 比如說已經完成四階段訓練的 Quan3-32B 或 235B 模型, 來指導這些比較小的學生模型。
Dialogue: 0,0:24:35.00,0:24:40.00,Default,,0,0,0,,老師帶學生, 聽起來不錯, 那具體是怎麼帶的呢?
Dialogue: 0,0:24:40.00,0:24:47.00,Default,,0,0,0,,主要有兩種方式, 他們都用上了。第一種叫做離策略蒸餾,off-policy distillation。
Dialogue: 0,0:24:47.00,0:25:01.00,Default,,0,0,0,,做法是先讓老師, 也就是大模型, 產生一大批高質量的範例答案, 這些答案包含了思考模式和非思考模式的, 然後讓學生、小模型直接學習這些範例。
Dialogue: 0,0:25:01.00,0:25:07.00,Default,,0,0,0,,就像是老師先把解題的標準步驟寫好, 讓學生照著模仿學習。
Dialogue: 0,0:25:07.00,0:25:08.00,Default,,0,0,0,,嗯, 學範本。
Dialogue: 0,0:25:08.00,0:25:13.00,Default,,0,0,0,,對, 第二種叫做再策略蒸餾,on-policy distillation。
Dialogue: 0,0:25:13.00,0:25:22.00,Default,,0,0,0,,這個方式比較動態一點, 讓學生、小模型自己嘗試去回答問題, 同時老師、大模型也在旁邊看著。
Dialogue: 0,0:25:22.00,0:25:26.00,Default,,0,0,0,,學生每生成一部答案, 就去看看老師是怎麼想的。
Dialogue: 0,0:25:26.00,0:25:40.00,Default,,0,0,0,,技術上是比較兩者輸出 Logits 的機率分布, 常用 KL 散度來衡量他們之間的差異, 然後學生就根據這個差異來調整自己, 讓自己的思路越來越接近老師的思路。
Dialogue: 0,0:25:40.00,0:25:46.00,Default,,0,0,0,,哦, 這個比較像學生自己動手做, 老師在旁邊即時指導修正。
Dialogue: 0,0:25:46.00,0:25:47.00,Default,,0,0,0,,對, 可以這麼理解。
Dialogue: 0,0:25:47.00,0:26:02.00,Default,,0,0,0,,所以, 蒸餾就像是走了一條捷徑, 用大模型的智慧來快速提升小模型的能力, 同時也教會了他們怎麼做思考模式的切換。那, 效果怎麼樣? 真的有比較有效率嗎?
Dialogue: 0,0:26:02.00,0:26:04.00,Default,,0,0,0,,效果非常好, 而且效率驚人。
Dialogue: 0,0:26:04.00,0:26:08.00,Default,,0,0,0,,報告裡給出的數據表 21 非常有說服力。
Dialogue: 0,0:26:08.00,0:26:22.00,Default,,0,0,0,,他們發現對於小型模型, 比如說 8B 參數的模型, 使用蒸餾方法, 不僅大大節省了計算資源, 報告宣稱只需要強化學習方法大約十分之一的 GPU 運算時間。
Dialogue: 0,0:26:22.00,0:26:24.00,Default,,0,0,0,,只要十分之一?
Dialogue: 0,0:26:24.00,0:26:39.00,Default,,0,0,0,,對, 而且更厲害的是, 在一些關鍵的機種測試, 像是 AMI 數學、Math 數學級, 還有程式碼能力測試上, 透過蒸餾訓練出來的小模型, 他們的分數甚至比用強化學習訓練出來的還要高。
Dialogue: 0,0:26:39.00,0:26:50.00,Default,,0,0,0,,誒, 等一下, 花的時間少很多, 結果效果還更好? 這, 這有點反直覺啊, 為什麼會這樣?
Dialogue: 0,0:26:50.00,0:26:53.00,Default,,0,0,0,,嗯, 這確實是一個蠻有趣的發現。
Dialogue: 0,0:26:53.00,0:27:07.00,Default,,0,0,0,,報告裡的推測是這樣的, 對於這些相對來說還比較小的模型, 強化學習可能需要進行大量的探索才能夠慢慢找到好的策略, 但這個探索的過程既昂貴, 又不一定每次都能成功找到最佳路徑。
Dialogue: 0,0:27:07.00,0:27:14.00,Default,,0,0,0,,相比之下, 有一個已經很強大的老師直接提供指導, 不論是給你看好的範例, 還是給你看好的模型。
Dialogue: 0,0:27:14.00,0:27:21.00,Default,,0,0,0,,但是即時糾正你的思路。對於小模型來說, 這可能是一個更直接、更有效的學習路徑。
Dialogue: 0,0:27:21.00,0:27:26.00,Default,,0,0,0,,它能幫助小模型更快地掌握那些複雜的推理技巧和模式切換的能力。
Dialogue: 0,0:27:26.00,0:27:34.00,Default,,0,0,0,,原來如此。所以真六不只是為了省成本, 對於小模型來說, 搞不好還是更好的學習方式。
Dialogue: 0,0:27:34.00,0:27:42.00,Default,,0,0,0,,這對於那些想要在資源比較有限的設備上部署 AI 應用的人來說, 是個非常重要的訊息啊。
Dialogue: 0,0:27:42.00,0:27:53.00,Default,,0,0,0,,好了, 經過了這麼一番精心的打磨, 不管是走完複雜四階段流程的大模型, 還是透過真六快速學習的小模型, 他們最終的表現到底如何?
Dialogue: 0,0:27:53.00,0:28:05.00,Default,,0,0,0,,包括裡面把這些經過指令微調之後的最終版本模型, 在思考和非思考兩種模式下, 拿去跟業界頂尖的幣源模型, 還有其他的開源模型, 進行了一場終極對決。
Dialogue: 0,0:28:05.00,0:28:10.00,Default,,0,0,0,,對我們聽眾來說, 最值得關注的結果是什麼? 哪些地方最亮眼?
Dialogue: 0,0:28:10.00,0:28:24.00,Default,,0,0,0,,嗯, 最重要的訊息就是, 千問三這個系列, 尤其是它的旗艦模型, 確實把自己推到了目前全球大型語言模型的第一梯隊, 展現出了非常強的競爭力。
Dialogue: 0,0:28:24.00,0:28:31.00,Default,,0,0,0,,我們分開來看, 首先是那個旗艦模型, 寬三 2125B-A22B。
Dialogue: 0,0:28:32.00,0:28:44.00,Default,,0,0,0,,在思考模式下, 你可以參考報告的表示儀, 它主要是跟其他特別強調推理能力的高手比較, 像是 OpenAI 的 o1, DeepSeek 的 r1, 還有 Grok 的 3 Beta 這些。
Dialogue: 0,0:28:44.00,0:28:54.00,Default,,0,0,0,,報告宣稱, 在目前的開源模型裡面, 千問三的這個旗艦模型, 達到了 SOTA, 也就是 States of the Art, 最強的水平。
Dialogue: 0,0:28:55.00,0:29:08.00,Default,,0,0,0,,整體表現來看, 報告說在 23 個基準測試中, 有 17 個領先。它優於 DeepSeek r1, 尤其在數學, 作為 Agent 應用, 還有程式碼任務方面更強。
Dialogue: 0,0:29:08.00,0:29:22.00,Default,,0,0,0,,而且別忘了, 它的啟用參數和總參數都比 DeepSeek r1 要少。同時, 它跟那些頂尖的幣源模型, 像是 o1 還有 Gemini 2.5 Pro, 它們之間的差距也顯著縮小了。
Dialogue: 0,0:29:22.00,0:29:45.00,Default,,0,0,0,,特別是在一些公認非常困難的測試上, 比如 AIME 數學競賽, 得分 85.7, 另一個 AIME 25,81.5,LiveCodeBench 程式碼競賽 5v5,70.7, 還有 BFCL v3,70.8, 以及 CodeForces 程式碼平台的評分達到 2056, 表現都非常亮眼。
Dialogue: 0,0:29:45.00,0:29:59.00,Default,,0,0,0,,聽起來, 在需要動腦筋深度思考的任務上, 這個千問三的旗艦模型真的很難打, 已經是開源界的領頭羊, 而且有能力跟那些幣源的巨頭掰掰手腕了。
Dialogue: 0,0:29:59.00,0:30:06.00,Default,,0,0,0,,那如果不用思考模式呢, 就把它當成一般的聊天模型來用, 表現怎麼樣?
Dialogue: 0,0:30:06.00,0:30:33.00,Default,,0,0,0,,這個結果我覺得更能顯現出它的厲害之處, 在非思考模式下, 參考報告表 12, 它們把哈根像是 GPT-4U,DeepSeek v3,Llama 4,Maverick 這些頂級的通用模型進行比較, 結果是, 它不僅超越了其他領先的開源模型, 報告甚至宣稱, 在比較的 23 個基準測試中, 有 18 個項目優於 GPT-4U, 它們用的是 2024 年 11 月 20 日那個版本。
Dialogue: 0,0:30:33.00,0:30:45.00,Default,,0,0,0,,哇, 連非思考模式下都能跟 GPT-4U 攪拌, 這表示它的基礎能力, 就是預訓練階段做得非常好, 非常紮實。
Dialogue: 0,0:30:45.00,0:30:56.00,Default,,0,0,0,,可以這麼說, 即使沒有特別去啟用那個比較耗資源的思考過程, 這個模型的基礎能力也非常強大, 通用性非常好。
Dialogue: 0,0:30:56.00,0:31:04.00,Default,,0,0,0,,嗯, 那中量級的模型呢? 譬如說, 那個 32B 的密集模型, 表現如何?
Dialogue: 0,0:31:04.00,0:31:19.00,Default,,0,0,0,,QN32B 這個模型的表現, 同樣令人印象深刻, 在思考模式下, 報告表 13, 它的表現超越了千問自己之前專門做推理的模型 QQ32B,
Dialogue: 0,0:31:19.00,0:31:34.00,Default,,0,0,0,,並且呢, 它能夠跟幣原的 OpenAI O3 Medium 這個級別的模型相抗衡, 尤其在對齊, 也就是理解人類指令的準確度, 和多語言能力方面, 甚至表現更好。
Dialogue: 0,0:31:34.00,0:31:42.00,Default,,0,0,0,,所以報告認為, 這是目前在 32B 這個參數規模下, 新的 SOTA 推理模型。
Dialogue: 0,0:31:42.00,0:31:45.00,Default,,0,0,0,,32B 級別的推理王?
Dialogue: 0,0:31:45.00,0:32:01.00,Default,,0,0,0,,對, 然後在非思考模式下, 報告表示是, 這個 32B 模型在幾乎所有的基準測試上, 也都優於跟它同級的比較對象, 像是 GPT-4ALL-MINI、拉瑪素、SCOUT 這些。
Dialogue: 0,0:32:01.00,0:32:22.00,Default,,0,0,0,,更值得注意的是, 它跟參數是它兩倍多的自家的前一代 QN2.5-72B INSTRUCT 這個模型相比, 雖然在一些比較通用的任務上表現相當, 但是在對齊能力、多語言處理, 還有一些需要推理能力的任務上,QN32B 有著明顯的優勢。
Dialogue: 0,0:32:23.00,0:32:34.00,Default,,0,0,0,,這就再次證明了,QN3 相較於 QN2.5 系列, 是一個根本性的、全面的進步, 而不只是參數變多而已。
Dialogue: 0,0:32:34.00,0:32:52.00,Default,,0,0,0,,看來這個 32B 的模型會是一個很有吸引力的甜點級選擇, 性能非常強勁, 又能保持相對的效率。那, 那些透過蒸餾技術訓練出來的更小的模型呢? 從 30B MODE 到 0.6B 的那些呢?
Dialogue: 0,0:32:52.00,0:33:07.00,Default,,0,0,0,,那些輕量級模型, 包括 30B MODE, 啟用 3B、14B、8B、4B、1.7B, 一直到最小的 0.6B, 你可以看報告的表 15-20, 它們也延續了這個強勁的趨勢。
Dialogue: 0,0:33:07.00,0:33:25.00,Default,,0,0,0,,無論是在思考模式還是非思考模式下, 這些模型普遍都優於參數規模相近, 甚至更大的競爭對手, 當然也包括了前代的千問 2.5 模型。這就有力的證明了, 強者對弱者蒸餾這個方法是非常成功的。
Dialogue: 0,0:33:25.00,0:33:42.00,Default,,0,0,0,,舉個例子, 那個 QWIN 34BA 3B 模型, 它在思考模式下, 只需要啟用遠少於 1% 的參數, 跟 32B 比的話是 3B 對 32B, 就能達到跟之前那個專門做推理的 QQQ 32B 模型差不多的性能。
Dialogue: 0,0:33:42.00,0:33:45.00,Default,,0,0,0,,哇, 這效率真的很高耶!
Dialogue: 0,0:33:45.00,0:34:00.00,Default,,0,0,0,,好, 總結一下我們剛剛討論的這些評測結果, 聽起來就是千問 3 這次是全線產品的戰鬥力都提升了一個檔次, 旗艦模型是開源街的新標杆, 有挑戰頂級幣圓模型。
Dialogue: 0,0:34:01.00,0:34:06.00,Default,,0,0,0,,重量級的 32B 模型性價比超高, 可能是新的黃金尺寸
Dialogue: 0,0:34:06.00,0:34:10.00,Default,,0,0,0,,而那些小模型也因為蒸餾技術而變得異常強大
Dialogue: 0,0:34:10.00,0:34:15.00,Default,,0,0,0,,而且那個思考模式確實能夠大幅提升需要動腦任務的表現
Dialogue: 0,0:34:15.00,0:34:21.00,Default,,0,0,0,,但即使在非思考模式下, 他們的通用能力也依然是頂尖水準
Dialogue: 0,0:34:21.00,0:34:25.00,Default,,0,0,0,,報告裡面還有一些討論到的細節, 我覺得也滿有意思的
Dialogue: 0,0:34:25.00,0:34:27.00,Default,,0,0,0,,值得我們再深入聊一下
Dialogue: 0,0:34:27.00,0:34:29.00,Default,,0,0,0,,比方說那個思考預算
Dialogue: 0,0:34:29.00,0:34:33.00,Default,,0,0,0,,我們前面提到說可以控制模型思考的深度
Dialogue: 0,0:34:33.00,0:34:37.00,Default,,0,0,0,,那多給他一些思考時間, 也就是 Token 預算
Dialogue: 0,0:34:37.00,0:34:40.00,Default,,0,0,0,,真的有用嗎? 效果怎麼樣?
Dialogue: 0,0:34:40.00,0:34:44.00,Default,,0,0,0,,這個問題報告裡用圖, 圖 2 來回答了
Dialogue: 0,0:34:44.00,0:34:49.00,Default,,0,0,0,,他們在數學、程式碼、STEM, 這些比較需要推理的任務上
Dialogue: 0,0:34:49.00,0:34:53.00,Default,,0,0,0,,測試了旗艦模型千萬 3、235、A2A2B
Dialogue: 0,0:34:53.00,0:34:56.00,Default,,0,0,0,,在不同思考 Token 預算下的表現
Dialogue: 0,0:34:56.00,0:35:01.00,Default,,0,0,0,,結果滿明顯的, 隨著你分配給思考過程的 Token 預算增加
Dialogue: 0,0:35:01.00,0:35:05.00,Default,,0,0,0,,模型的性能分數普遍呈現出一個平穩上升的趨勢
Dialogue: 0,0:35:05.00,0:35:08.00,Default,,0,0,0,,所以預算越多, 想得越好
Dialogue: 0,0:35:08.00,0:35:10.00,Default,,0,0,0,,對, 基本上是這樣
Dialogue: 0,0:35:10.00,0:35:13.00,Default,,0,0,0,,這表示多給他一些運算資源去想
Dialogue: 0,0:35:13.00,0:35:15.00,Default,,0,0,0,,確實能夠得到更好的結果
Dialogue: 0,0:35:15.00,0:35:17.00,Default,,0,0,0,,報告還稍微暗示了一下
Dialogue: 0,0:35:17.00,0:35:20.00,Default,,0,0,0,,如果未來能夠支援更長的上下文長度
Dialogue: 0,0:35:20.00,0:35:22.00,Default,,0,0,0,,給予更高的思考預算
Dialogue: 0,0:35:22.00,0:35:25.00,Default,,0,0,0,,那性能可能還有進一步提升的空間
Dialogue: 0,0:35:25.00,0:35:29.00,Default,,0,0,0,,對你來說, 這就意味著未來在使用這類模型的時候
Dialogue: 0,0:35:29.00,0:35:31.00,Default,,0,0,0,,或許真的可以根據自己的需求
Dialogue: 0,0:35:31.00,0:35:33.00,Default,,0,0,0,,看你是要快還是要好
Dialogue: 0,0:35:33.00,0:35:36.00,Default,,0,0,0,,在速度和品質之間做個權衡
Dialogue: 0,0:35:36.00,0:35:38.00,Default,,0,0,0,,這確實給了使用者更多的彈性
Dialogue: 0,0:35:38.00,0:35:40.00,Default,,0,0,0,,另一個我們剛剛也提到
Dialogue: 0,0:35:40.00,0:35:42.00,Default,,0,0,0,,但我覺得值得再強調一次的
Dialogue: 0,0:35:42.00,0:35:44.00,Default,,0,0,0,,是那個徵流的效率
Dialogue: 0,0:35:44.00,0:35:47.00,Default,,0,0,0,,你剛剛說小模型用徵流訓練
Dialogue: 0,0:35:47.00,0:35:52.00,Default,,0,0,0,,GPU 運算時間只需要強化學習的大約 1%
Dialogue: 0,0:35:52.00,0:35:54.00,Default,,0,0,0,,而且得到的分數還可能更高
Dialogue: 0,0:35:54.00,0:35:56.00,Default,,0,0,0,,正是如此
Dialogue: 0,0:35:56.00,0:36:00.00,Default,,0,0,0,,報告裡的數據表 21 非常清楚地顯示了這一點
Dialogue: 0,0:36:00.00,0:36:03.00,Default,,0,0,0,,特別是對於 8B 這種規模的模型
Dialogue: 0,0:36:03.00,0:36:05.00,Default,,0,0,0,,不只是最終的分數可能更高
Dialogue: 0,0:36:05.00,0:36:06.00,Default,,0,0,0,,他們還發現
Dialogue: 0,0:36:06.00,0:36:08.00,Default,,0,0,0,,透過徵流訓練出來的模型
Dialogue: 0,0:36:08.00,0:36:11.00,Default,,0,0,0,,在所謂的探索潛力上也表現更好
Dialogue: 0,0:36:11.00,0:36:14.00,Default,,0,0,0,,他們用一個叫做 pass at 64 的指標來衡量
Dialogue: 0,0:36:14.00,0:36:18.00,Default,,0,0,0,,這個指標越高代表模型能生成更多樣化
Dialogue: 0,0:36:18.00,0:36:20.00,Default,,0,0,0,,並且有可能是正確的答案
Dialogue: 0,0:36:21.00,0:36:22.00,Default,,0,0,0,,這似乎說明了
Dialogue: 0,0:36:22.00,0:36:25.00,Default,,0,0,0,,對於這些還不夠強大的小模型來說
Dialogue: 0,0:36:25.00,0:36:28.00,Default,,0,0,0,,有一個好的老師來引導方向
Dialogue: 0,0:36:28.00,0:36:30.00,Default,,0,0,0,,可能比讓他們自己跌跌撞撞地
Dialogue: 0,0:36:30.00,0:36:32.00,Default,,0,0,0,,用強化學習去摸索
Dialogue: 0,0:36:32.00,0:36:33.00,Default,,0,0,0,,是更有效率
Dialogue: 0,0:36:33.00,0:36:36.00,Default,,0,0,0,,也更能激發潛力的學習方式
Dialogue: 0,0:36:36.00,0:36:37.00,Default,,0,0,0,,了解
Dialogue: 0,0:36:37.00,0:36:40.00,Default,,0,0,0,,那整個後訓練的過程
Dialogue: 0,0:36:40.00,0:36:44.00,Default,,0,0,0,,是不是也存在一些取捨
Dialogue: 0,0:36:44.00,0:36:49.00,Default,,0,0,0,,我看報告裡表 22 有比較那個 32B 模型
Dialogue: 0,0:36:49.00,0:36:53.00,Default,,0,0,0,,在經歷了不同訓練階段之後的表現變化
Dialogue: 0,0:36:53.00,0:36:56.00,Default,,0,0,0,,從只做滿推理強化學習階段 2
Dialogue: 0,0:36:56.00,0:36:59.00,Default,,0,0,0,,到融合了非思考模式階段 3
Dialogue: 0,0:36:59.00,0:37:03.00,Default,,0,0,0,,再到最後完成了通用強化學習階段 4
Dialogue: 0,0:37:03.00,0:37:07.00,Default,,0,0,0,,這裡面是不是有什麼值得注意的地方
Dialogue: 0,0:37:07.00,0:37:08.00,Default,,0,0,0,,你觀察得很仔細
Dialogue: 0,0:37:08.00,0:37:11.00,Default,,0,0,0,,這裡就體現了大型模型訓練過程中
Dialogue: 0,0:37:11.00,0:37:14.00,Default,,0,0,0,,常常需要做的平衡的藝術
Dialogue: 0,0:37:14.00,0:37:15.00,Default,,0,0,0,,結果顯示
Dialogue: 0,0:37:15.00,0:37:18.00,Default,,0,0,0,,階段 3 融合思考非思考模式
Dialogue: 0,0:37:18.00,0:37:21.00,Default,,0,0,0,,和階段 4 通用強化學習
Dialogue: 0,0:37:21.00,0:37:23.00,Default,,0,0,0,,確實顯著提升了模型
Dialogue: 0,0:37:23.00,0:37:25.00,Default,,0,0,0,,在很多實用性方面的能力
Dialogue: 0,0:37:25.00,0:37:26.00,Default,,0,0,0,,比如說
Dialogue: 0,0:37:26.00,0:37:28.00,Default,,0,0,0,,模型是不是更能準確理解
Dialogue: 0,0:37:28.00,0:37:30.00,Default,,0,0,0,,並執行複雜的指令
Dialogue: 0,0:37:30.00,0:37:33.00,Default,,0,0,0,,是不是更能夠按照你要求的長度
Dialogue: 0,0:37:33.00,0:37:34.00,Default,,0,0,0,,或格式來輸出
Dialogue: 0,0:37:34.00,0:37:36.00,Default,,0,0,0,,他們用了像是 IFL
Dialogue: 0,0:37:36.00,0:37:37.00,Default,,0,0,0,,MultiIF
Dialogue: 0,0:37:37.00,0:37:39.00,Default,,0,0,0,,Length Control
Dialogue: 0,0:37:39.00,0:37:41.00,Default,,0,0,0,,這些指標分數都提高了
Dialogue: 0,0:37:42.00,0:37:45.00,Default,,0,0,0,,模型能不能很可靠的根據你的指令
Dialogue: 0,0:37:45.00,0:37:47.00,Default,,0,0,0,,像是 THINK 標籤
Dialogue: 0,0:37:47.00,0:37:50.00,Default,,0,0,0,,來切換思考或非思考模式
Dialogue: 0,0:37:50.00,0:37:52.00,Default,,0,0,0,,有個叫 THINK FOLLOW 的指標
Dialogue: 0,0:37:52.00,0:37:55.00,Default,,0,0,0,,在階段 4 之後達到了 98.9%
Dialogue: 0,0:37:55.00,0:37:57.00,Default,,0,0,0,,表示切換非常可靠
Dialogue: 0,0:37:59.00,0:38:02.00,Default,,0,0,0,,還有模型能不能處理那些有點刁鑽的
Dialogue: 0,0:38:02.00,0:38:04.00,Default,,0,0,0,,跟事實相反的提問
Dialogue: 0,0:38:04.00,0:38:07.00,Default,,0,0,0,,有個叫 Counterfact QA 的指標
Dialogue: 0,0:38:07.00,0:38:08.00,Default,,0,0,0,,分數也提高了
Dialogue: 0,0:38:08.00,0:38:10.00,Default,,0,0,0,,以及模型作為 Agent
Dialogue: 0,0:38:10.00,0:38:13.00,Default,,0,0,0,,使用外部工具的能力是不是變強了
Dialogue: 0,0:38:13.00,0:38:14.00,Default,,0,0,0,,用了 Tool Use
Dialogue: 0,0:38:14.00,0:38:16.00,Default,,0,0,0,,BFCL 這些指標
Dialogue: 0,0:38:16.00,0:38:18.00,Default,,0,0,0,,分數也是提高的
Dialogue: 0,0:38:18.00,0:38:20.00,Default,,0,0,0,,聽起來階段 3、4
Dialogue: 0,0:38:20.00,0:38:22.00,Default,,0,0,0,,讓模型變得更聽話
Dialogue: 0,0:38:22.00,0:38:23.00,Default,,0,0,0,,更全面
Dialogue: 0,0:38:23.00,0:38:24.00,Default,,0,0,0,,更可靠了
Dialogue: 0,0:38:24.00,0:38:26.00,Default,,0,0,0,,那代價是什麼
Dialogue: 0,0:38:26.00,0:38:29.00,Default,,0,0,0,,代價就是天下沒有白吃的午餐嘛
Dialogue: 0,0:38:29.00,0:38:32.00,Default,,0,0,0,,為了獲得這些廣泛的實用性提升
Dialogue: 0,0:38:32.00,0:38:34.00,Default,,0,0,0,,模型在那些最頂尖
Dialogue: 0,0:38:34.00,0:38:36.00,Default,,0,0,0,,最困難的純粹推理任務上
Dialogue: 0,0:38:36.00,0:38:38.00,Default,,0,0,0,,像是我們前面提到的
Dialogue: 0,0:38:38.00,0:38:40.00,Default,,0,0,0,,AIME 數學競賽
Dialogue: 0,0:38:40.00,0:38:42.00,Default,,0,0,0,,LifeCodeBench 程式碼競賽
Dialogue: 0,0:38:42.00,0:38:44.00,Default,,0,0,0,,它的表現在思考模式下
Dialogue: 0,0:38:44.00,0:38:47.00,Default,,0,0,0,,反而略微下降了一點點
Dialogue: 0,0:38:47.00,0:38:48.00,Default,,0,0,0,,哦
Dialogue: 0,0:38:48.00,0:38:51.00,Default,,0,0,0,,所以為了讓模型變成一個更聽話
Dialogue: 0,0:38:51.00,0:38:52.00,Default,,0,0,0,,更全能
Dialogue: 0,0:38:52.00,0:38:54.00,Default,,0,0,0,,更可靠的多面手
Dialogue: 0,0:38:54.00,0:38:56.00,Default,,0,0,0,,稍微犧牲了一點點
Dialogue: 0,0:38:56.00,0:38:59.00,Default,,0,0,0,,在極端困難問題上的巔峯解體能力
Dialogue: 0,0:38:59.00,0:39:02.00,Default,,0,0,0,,這聽起來是一個很重要的設計上的抉擇
Dialogue: 0,0:39:02.00,0:39:03.00,Default,,0,0,0,,對
Dialogue: 0,0:39:03.00,0:39:04.00,Default,,0,0,0,,可以這麼理解
Dialogue: 0,0:39:04.00,0:39:06.00,Default,,0,0,0,,團隊在報告中也直接承認
Dialogue: 0,0:39:06.00,0:39:08.00,Default,,0,0,0,,這是一種權衡
Dialogue: 0,0:39:08.00,0:39:09.00,Default,,0,0,0,,Tradeoff
Dialogue: 0,0:39:09.00,0:39:11.00,Default,,0,0,0,,他們選擇了讓最終發布的模型
Dialogue: 0,0:39:11.00,0:39:15.00,Default,,0,0,0,,在整體的通用性、穩定性和易用性上
Dialogue: 0,0:39:15.00,0:39:17.00,Default,,0,0,0,,達到一個最佳的平衡點
Dialogue: 0,0:39:17.00,0:39:21.00,Default,,0,0,0,,即使這意味著在某些純粹的智力競賽項目上
Dialogue: 0,0:39:21.00,0:39:24.00,Default,,0,0,0,,沒有達到理論上可能的最高分數
Dialogue: 0,0:39:24.00,0:39:25.00,Default,,0,0,0,,嗯
Dialogue: 0,0:39:25.00,0:39:27.00,Default,,0,0,0,,這對使用者來說意味著什麼呢
Dialogue: 0,0:39:27.00,0:39:28.00,Default,,0,0,0,,如果
Dialogue: 0,0:39:28.00,0:39:52.00,Default,,0,0,0,,如果你追求的是在某個特定領域, 比如數學競賽, 達到極致的推理性能, 或許只經過階段二或階段三訓練的模型在那個特定任務上會更強一點, 但如果你需要的是一個在各方面都表現良好、更穩定可靠、更容易使用的通用模型, 那麼經過完整四階段訓練的最終版本會是更好的選擇。
Dialogue: 0,0:39:52.00,0:40:16.00,Default,,0,0,0,,這個細節很重要, 提醒我們評估模型不能只看單一最高分, 而是要看它在多個目標之間是如何取得平衡的。那還有兩個領域, 我們前面稍微提到過常文本處理和多語言能力, 報告裡有沒有更深入的觀察? 我記得有提到一個叫做 RULER 的常文本基準測試。
Dialogue: 0,0:40:16.00,0:40:45.00,Default,,0,0,0,,對, 報告表 23 裡面展示了模型在 RULER 這個測試上的結果, 涵蓋了高達 128K Token 的上下文長度。總體來說, 在非思考模式下, 千問三的模型通常比同等規模的千問二連五表現要好, 性能在 32K 和 64K 這兩種長度下維持的還算不錯, 但是到了 128K 這個超長的長度時, 性能下降就比較明顯了。
Dialogue: 0,0:40:45.00,0:40:53.00,Default,,0,0,0,,嗯,128K 確實非常長了, 能處理已經很不容易。還有其他的發現嗎? 關於常文本的。
Dialogue: 0,0:40:53.00,0:41:04.00,Default,,0,0,0,,有一個滿有趣的現象, 在這個 RULER 測試上, 研究人員發現, 啟用思考模式反而讓模型的性能略微下降了。
Dialogue: 0,0:41:04.00,0:41:11.00,Default,,0,0,0,,誒, 又下降了, 這跟之前看到思考模式能提升推理能力的結果是相反的啊。
Dialogue: 0,0:41:11.00,0:41:26.00,Default,,0,0,0,,對, 這點他們也注意到了。團隊推測說, 像 RULER 這類的基準測試, 可能更側重於從長篇的文當中快速準確地找出特定的資訊, 而不是進行複雜的推理或分析。
Dialogue: 0,0:41:26.00,0:41:35.00,Default,,0,0,0,,在這種情況下, 模型額外生成的那些思考過程的內容可能反而干擾了它定位關鍵資訊的能力, 變成了一種噪音。
Dialogue: 0,0:41:35.00,0:41:38.00,Default,,0,0,0,,哦, 想太多反而礙事了。
Dialogue: 0,0:41:38.00,0:41:50.00,Default,,0,0,0,,對, 有點這個意思。這是他們認為未來需要改進的地方, 如何在長文本的資訊檢索任務和需要深度思考的任務之間, 讓思考模式能更好的協同運作, 而不是互相干擾。
Dialogue: 0,0:41:50.00,0:42:03.00,Default,,0,0,0,,這也蠻合理的。那多語言方面呢? 除了支援的語言數量大增到 119 種, 實際表現如何? 報告裡好像有很多針對不同語言的詳細表格。
Dialogue: 0,0:42:03.00,0:42:23.00,Default,,0,0,0,,是的, 報告提供了非常非常詳細的數據, 你可以去看表 24-35, 他們分解了模型在像是西班牙語、法語、德語、俄語、阿拉伯語、日語、韓語、越南語等等多種不同語言上的具體分數。
Dialogue: 0,0:42:24.00,0:42:41.00,Default,,0,0,0,,涵蓋的測試基準也很多樣, 有測試多指令遵循的 Multi-IF, 測試邏輯推理的 MLogic QA, 常識問答的 MMMLU, 甚至還有多元版本的數學競賽 MTAME24 等等。
Dialogue: 0,0:42:41.00,0:42:46.00,Default,,0,0,0,,嗯, 看起來很全面。那總體來說呢, 有沒有一個概括性的比較?
Dialogue: 0,0:42:46.00,0:43:05.00,Default,,0,0,0,,有的, 如果我們看一個更宏觀的比較, 比如說 Balabalay 這個避準測試, 它涵蓋了 80 種不同的語言, 報告表 37, 結果顯示千問三模型與同等規模的 JAMMA 模型表現是相當的, 並且顯著優於自家的前一代千問 2.5 模型。
Dialogue: 0,0:43:06.00,0:43:16.00,Default,,0,0,0,,這就再次證實了, 使用更龐大、更多樣化的多語言數據進行預訓練, 確實有效地提升了模型的跨語言理解和生成能力。
Dialogue: 0,0:43:16.00,0:43:32.00,Default,,0,0,0,,好, 我們今天真的聊了非常多關於千問三的細節, 從它的設計理念, 怎麼訓練出來的, 到基礎模型和最終模型的評測結果, 還有一些像是思考預算、蒸餾效率、訓練取捨等等有趣的發現。
Dialogue: 0,0:43:32.00,0:43:42.00,Default,,0,0,0,,那麼總結一下, 對正在收聽的你來說, 這一切到底意味著什麼? 我們可以從千問三的發布看到哪些重要的趨勢呢?
Dialogue: 0,0:43:42.00,0:43:50.00,Default,,0,0,0,,我覺得, 千問三的發布, 代表了開源大型語言模型這個領域又往前邁出了很重要的一步。
Dialogue: 0,0:43:50.00,0:43:58.00,Default,,0,0,0,,它不只是在性能上, 尤其是在旗艦模型的部分, 設定了一個新的標桿, 展現了非常強大的競爭力。
Dialogue: 0,0:43:58.00,0:44:02.00,Default,,0,0,0,,更重要的是, 它引入了一些蠻新穎的概念和功能。
Dialogue: 0,0:44:03.00,0:44:13.00,Default,,0,0,0,,像是那個整合在一起的思考模式跟非思考模式, 還有可以調整的思考預算, 感覺讓模型的使用方式變得更有彈性了。
Dialogue: 0,0:44:13.00,0:44:29.00,Default,,0,0,0,,正是如此, 這讓模型有潛力能夠同時應對需要快速反應的問答和需要深度推理的複雜人物, 並且它給了使用者一定的控制權, 讓你可以根據需求在速度和品質之間做選擇。
Dialogue: 0,0:44:29.00,0:44:32.00,Default,,0,0,0,,另外, MoE 架構這次成功的應用
Dialogue: 0,0:44:32.00,0:44:36.00,Default,,0,0,0,,還有強者對弱者蒸餾這個技術所展現出來的高效率
Dialogue: 0,0:44:36.00,0:44:40.00,Default,,0,0,0,,也為未來開發更強大同時更有效率的模型
Dialogue: 0,0:44:40.00,0:44:42.00,Default,,0,0,0,,特別是那些比較小型的模型
Dialogue: 0,0:44:42.00,0:44:44.00,Default,,0,0,0,,提供了非常重要的參考路徑
Dialogue: 0,0:44:44.00,0:44:45.00,Default,,0,0,0,,而且不要忘了
Dialogue: 0,0:44:45.00,0:44:49.00,Default,,0,0,0,,他們全部都是用 Apache 2.0 授權開源的
Dialogue: 0,0:44:49.00,0:44:52.00,Default,,0,0,0,,這一點對整個社羣來說真的很加分
Dialogue: 0,0:44:52.00,0:44:53.00,Default,,0,0,0,,的確
Dialogue: 0,0:44:53.00,0:44:56.00,Default,,0,0,0,,這大大降低了大家去使用、研究
Dialogue: 0,0:44:56.00,0:45:00.00,Default,,0,0,0,,甚至是在它的基礎上進行二次開發的門檻
Dialogue: 0,0:45:00.00,0:45:02.00,Default,,0,0,0,,從 Qwen3 這份技術報告中
Dialogue: 0,0:45:02.00,0:45:05.00,Default,,0,0,0,,我們其實也看到了大型模型開發過程中
Dialogue: 0,0:45:05.00,0:45:09.00,Default,,0,0,0,,無所不在的那種平衡的藝術
Dialogue: 0,0:45:09.00,0:45:11.00,Default,,0,0,0,,如何在提升推理能力的同時
Dialogue: 0,0:45:11.00,0:45:16.00,Default,,0,0,0,,不犧牲掉模型的通用性和遵循指令的能力
Dialogue: 0,0:45:16.00,0:45:19.00,Default,,0,0,0,,如何在追求極致性能的同時
Dialogue: 0,0:45:19.00,0:45:22.00,Default,,0,0,0,,也要兼顧訓練和實際推理時的效率
Dialogue: 0,0:45:22.00,0:45:25.00,Default,,0,0,0,,如何在擴展多語言能力的同時
Dialogue: 0,0:45:25.00,0:45:29.00,Default,,0,0,0,,確保在各種語言上的表現水準都能維持
Dialogue: 0,0:45:29.00,0:45:32.00,Default,,0,0,0,,這些都是 Qwen3 團隊試圖在這一代模型中
Dialogue: 0,0:45:32.00,0:45:35.00,Default,,0,0,0,,去應對和平衡的挑戰
Dialogue: 0,0:45:35.00,0:45:36.00,Default,,0,0,0,,說得很好
Dialogue: 0,0:45:36.00,0:45:40.00,Default,,0,0,0,,那麼最後基於我們今天討論的這麼多內容
Dialogue: 0,0:45:40.00,0:45:43.00,Default,,0,0,0,,我想留給你一個值得繼續思考的問題
Dialogue: 0,0:45:43.00,0:45:46.00,Default,,0,0,0,,報告裡面提到了他們未來的研究方向
Dialogue: 0,0:45:46.00,0:45:49.00,Default,,0,0,0,,包括會繼續擴大訓練資料的規模
Dialogue: 0,0:45:49.00,0:45:51.00,Default,,0,0,0,,改進模型本身的架構
Dialogue: 0,0:45:51.00,0:45:52.00,Default,,0,0,0,,比如做模型壓縮
Dialogue: 0,0:45:52.00,0:45:54.00,Default,,0,0,0,,處理更長的文本等等
Dialogue: 0,0:45:54.00,0:45:57.00,Default,,0,0,0,,還有就是要強化 agent 的能力
Dialogue: 0,0:45:57.00,0:46:00.00,Default,,0,0,0,,讓模型能更好的跟外部環境互動
Dialogue: 0,0:46:00.00,0:46:02.00,Default,,0,0,0,,使用工具來完成任務
Dialogue: 0,0:46:02.00,0:46:05.00,Default,,0,0,0,,那考慮到我們今天看到的那個現象就是
Dialogue: 0,0:46:05.00,0:46:09.00,Default,,0,0,0,,為了提升模型的通用性而進行的後訓練
Dialogue: 0,0:46:09.00,0:46:12.00,Default,,0,0,0,,特別是最後那個通用強化學習階段
Dialogue: 0,0:46:12.00,0:46:16.00,Default,,0,0,0,,反而可能會略為降低模型在最頂尖
Dialogue: 0,0:46:16.00,0:46:18.00,Default,,0,0,0,,最純粹的推理任務上的表現
Dialogue: 0,0:46:18.00,0:46:21.00,Default,,0,0,0,,未來當模型需要具備更強的自主性
Dialogue: 0,0:46:21.00,0:46:25.00,Default,,0,0,0,,能夠執行更複雜多步驟的 agent 的任務時
Dialogue: 0,0:46:25.00,0:46:29.00,Default,,0,0,0,,訓練技術要如何在模型的專業領域卓越性
Dialogue: 0,0:46:29.00,0:46:33.00,Default,,0,0,0,,比如說極致的數學或程式碼能力
Dialogue: 0,0:46:33.00,0:46:36.00,Default,,0,0,0,,和它廣泛的通用能力與可靠性之間
Dialogue: 0,0:46:36.00,0:46:39.00,Default,,0,0,0,,取得一個更好更智能的平衡呢
Dialogue: 0,0:46:39.00,0:46:42.00,Default,,0,0,0,,這是一個非常值得我們持續關注的發展方向
Dialogue: 0,0:46:42.00,0:46:44.00,Default,,0,0,0,,好非常感謝你今天和我們一起
Dialogue: 0,0:46:44.00,0:46:47.00,Default,,0,0,0,,花了這麼多時間深入了解前文三
Dialogue: 0,0:46:47.00,0:46:49.00,Default,,0,0,0,,希望這次的討論對你有幫助
Dialogue: 0,0:46:49.00,0:46:52.00,Default,,0,0,0,,我們下次寶格帶你聽再見囉
Dialogue: 0,0:46:52.00,0:46:52.00,Default,,0,0,0,,掰掰
Dialogue: 0,0:47:19.00,0:47:21.00,Default,,0,0,0,,採訪撰稿 —— 王維
Dialogue: 0,0:47:49.00,0:47:51.00,Default,,0,0,0,,採訪撰稿 —— 王維
Dialogue: 0,0:48:19.00,0:48:21.00,Default,,0,0,0,,比如做模型壓縮
Dialogue: 0,0:48:21.00,0:48:23.00,Default,,0,0,0,,處理更長的文本等等
Dialogue: 0,0:48:23.00,0:48:25.00,Default,,0,0,0,,還有就是要強化 agent 的能力
Dialogue: 0,0:48:25.00,0:48:28.00,Default,,0,0,0,,讓模型能夠好地跟外部環境互動
Dialogue: 0,0:48:28.00,0:48:30.00,Default,,0,0,0,,使用工具來完成任務
Dialogue: 0,0:48:30.00,0:48:33.00,Default,,0,0,0,,那考慮到我們今天看到的那個現象就是
